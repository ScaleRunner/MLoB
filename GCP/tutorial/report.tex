\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{listings}
\usepackage{graphicx}
\usepackage{float}
\usepackage{hyperref} 
\usepackage{subcaption}
\usepackage{lmodern}  % for bold teletype font
\usepackage[fleqn]{amsmath}  % for \hookrightarrow
\usepackage{xcolor}   % for \textcolor
\usepackage{dirtree}

\graphicspath{ {images/} }

\title{Training ML models using GCP}
\author{Mick van Hulst \and Dennis Verheijden}
\begin{document}
\maketitle

\section{Introduction}
This document describes a tutorial which can be used for connecting with GCP (Google Cloud Platform) and sending training jobs to Cloud ML. The folder with name 'templates' contains several templates. You can use these templates to train your models on Cloud ML. 
\\
\\
\textit{Note: }This tutorial assumes that you're using Keras to train your models. If you're using a different package, then you'll have to change the template 'train.py'.

\section{GCP setup}
As a preparation the TA's have created several containers\footnote{Basically a folder which can be assigned to specific users. This makes it possible to assign a container to each specific group. These folders/containers are used as a mechanism to save your data files and resulting models.} on GCP. The TA's have assigned a container to each group.
\\
\\
To work with GCP you'll need to install their SDK (using the following \hyperlink{https://cloud.google.com/sdk/docs/}{tutorial}). This tutorial will prompt you to select a project for which you'll have to select 'Pilot project 1'.

\section{Upload training data}
To train your model, you first have to send your training data to GCP. This can be done in a number of ways, most people will probably want to send a folder (with train, test and maybe validation data). This can be done using the following (terminal) command:

\begin{verbatim}
gsutil cp -r data_dir gs://container_name
\end{verbatim}

Where \texttt{data\_dir} is the local directory where the files are stored. You can also specify where the files have to be saved, by adjusting the destination url, for example to: \texttt{gs://container\_name/data}.

For copying separate files you can remove the \texttt{-r} (recursive) parameter and specify file source and destination:
\begin{verbatim}
gsutil cp -r local_path_to_file/file.extension \
gs://container_name/file.extension
\end{verbatim}

Downloading data can be done by switching the \textbf{gs://url} with the local folder.

\section{Folder structure and templates}
Use the following folder structure for training your model on GCP:
\begin{figure}[H]
\dirtree{%
.1 root.
.2 trainer.
.3 \_\_init\_\_.py.
.3 train.py.
.3 config.yaml.
.2 setup.py.
}
\caption{Folder structure GCP}
\label{fig:fsgcp}
\end{figure}
\subsection{Use cases files}
The file \texttt{\_\_init\_\_.py} is an empty initialization file.
\\
\\
The file \texttt{train.py} is a template which can be used to combine your model with the structure needed to use GCP. The remainder of this tutorial assumes that you're using this template.
\\
\\
The file \texttt{config.yaml} is a file which can be used to adjust the amount of GPU's you want to use during training. 
\\
\\
The file \texttt{setup.py} is a file that GCP uses to check which packages you want to use. Make sure to add all packages that you're using (excluding the standard Python packages) to this file.

\section{Training your model}
\subsection{Local}
Training your model locally with a small dataset is wise as it allows you to test your model after amending the changes which are described above. To test your model locally, use the following command:

\begin{verbatim}
gcloud ml-engine local train --module-name trainer.train \ 
--package-path path_to_root/trainer -- \
--train-file path_to_local_train_file/train_file.extension \
--job-dir ./tmp/test_script_gcp
\end{verbatim}


\subsection{Cloud}
To test your model in the cloud use the following command, where the job name needs to be unique and where the region should correspond to the region of your container (region can be found at your container page on GCP):
\begin{verbatim}
gcloud ml-engine jobs submit training job_name --stream-logs \
--runtime-version 1.4 --job-dir gs://container_name/job_name \
--package-path path_to_root/trainer --module-name trainer.train \
--region region_name  --config path_to_root/trainer/config.yaml \
-- \
--train-file gs://container_name/data_file.extension
\end{verbatim}
After the `empty' parameter (\texttt{--}), you may add your own parameters that can be passed to the trainer. \\
\\
During training you can look monitor the progress of your model by navigating to the 'Logging' page at your GCP console. Make sure to apply a correct filter so that you only see logging data from the current job.
\\
\\
After training, you can use your model to make predictions. You'll have to download your model first and then make the predictions locally. Use the following command to download your model:
\begin{verbatim}
gsutil cp gs://container_name/job_name/model.h5 local_folder/
\end{verbatim}

\end{document}

